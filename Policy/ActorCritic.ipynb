{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actor Critic Network\n",
    "\n",
    "Both value and policy based methods have big drawbacks. That's why we use \"hybrid method\" Actor Critic, which has two networks:\n",
    "- a Critic which measures how good the taken action is\n",
    "- an Actor that controls how our agent behaves\n",
    "\n",
    "The Policy Gradient method has a big problem because of Monte Carlo, which waits until the end of episode to calculate the reward. We may conclude that if we have a high reward $R(t)$, all actions that we took were good, even if some were really bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor Critic\n",
    "\n",
    "Instead of waiting until the end of the episode as we do in Monte Carlo REINFORCE, we make an update at each step (TD Learning).\n",
    "\n",
    "Because we do an update at each time step, we can't use the total rewards $R(t)$. Instead, we need to train a Critic model that approximates the Q-value function. This value function replaces the reward function in policy gradient that calculates the rewards only at the end of the episode.\n",
    "\n",
    "Because we have two models (Actor and Critic) that must be trained, it means that we have two set of weights ($\\theta$ for our action and $w$ for our Critic) that must be optimized separately:\n",
    "$$\\Delta \\theta = \\alpha_1 \\nabla_{\\theta}(\\log \\pi_{\\theta}(s, a)) q_{w}(s, a)$$\n",
    "$$\\Delta w = \\alpha_2 \\nabla_{w} L(R(s, a) + \\lambda q_{w}(s_{t + 1}, a_{t + 1}), q_{w}(s_t - a_t))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantage Actor Critic\n",
    "\n",
    "Value-based methods have high variability. To reduce this problem we use advantage function instead of value function:\n",
    "$$A(s, a) = Q(s, a) - V(s)$$\n",
    "where $V(s)$ is average value of that state. This function will tell us the improvement compared to the average the action taken at that state is.\n",
    "\n",
    "The problem of implementing this advantage function is that is requires two value functions  -  $Q(s,a)$ and $V(s)$. Fortunately, we can use the TD error as a good estimator of the advantage function:\n",
    "$$A(s, a) = Q(s, a) - V(s) = r + \\lambda V(s') - V(s)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:37:33.555236Z",
     "start_time": "2018-11-01T17:37:33.535039Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:15:52.166009Z",
     "start_time": "2018-11-01T17:15:52.080455Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 40\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:16:59.095695Z",
     "start_time": "2018-11-01T17:16:59.016713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space size: 2\n",
      "State space size: 4\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\")\n",
    "\n",
    "a_size = env.action_space.n\n",
    "s_size = env.observation_space.shape[0]\n",
    "\n",
    "print(\"Action space size: {}\".format(a_size))\n",
    "print(\"State space size: {}\".format(s_size))\n",
    "\n",
    "possible_actions = np.identity(a_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:35:57.427448Z",
     "start_time": "2018-11-01T17:35:57.380448Z"
    }
   },
   "outputs": [],
   "source": [
    "class A2CNetwork(object):\n",
    "    def __init__(self, s_size, a_size, learning_rate=0.01):\n",
    "        self.a_size = a_size\n",
    "        self.s_size = s_size\n",
    "        \n",
    "        self.states = tf.placeholder(shape=[None, s_size], dtype=tf.float32)\n",
    "        self.dense = tf.layers.dense(inputs=self.states, units=32, activation=tf.nn.relu)\n",
    "        self.policy = tf.layers.dense(inputs=self.dense, units=self.a_size, activation=tf.nn.softmax)\n",
    "        self.value = tf.layers.dense(inputs=self.dense, units=1)\n",
    "        \n",
    "        self.actions = tf.placeholder(shape=[None, a_size], dtype=tf.float32)\n",
    "        self.target_values = tf.placeholder(shape=[None,], dtype=tf.float32)\n",
    "        self.advantages = tf.placeholder(shape=[None,], dtype=tf.float32)\n",
    "        \n",
    "        # policy loss\n",
    "        log_prob = tf.log(tf.clip_by_value(self.policy, 0.000001, 0.999999))\n",
    "        neg_log_responsible_policy = -tf.reduce_sum(tf.multiply(log_prob, self.actions), reduction_indices=1)\n",
    "        self.policy_loss = tf.reduce_mean(tf.multiply(neg_log_responsible_policy, self.advantages))\n",
    "        \n",
    "        # value loss\n",
    "        self.value_loss = tf.reduce_mean(tf.square(self.target_values - self.value))\n",
    "        \n",
    "        #loss\n",
    "        self.loss = self.value_loss + self.policy_loss\n",
    "        \n",
    "        trainer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        self.optimize = trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:36:10.489812Z",
     "start_time": "2018-11-01T17:36:10.115045Z"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "network = A2CNetwork(s_size, a_size)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T17:36:27.118386Z",
     "start_time": "2018-11-01T17:36:27.031538Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T18:03:28.047510Z",
     "start_time": "2018-11-01T18:03:27.775665Z"
    }
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?]\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_2', defined at:\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 346, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 259, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 513, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-f7c785481313>\", line 3, in <module>\n    network = A2CNetwork(s_size, a_size)\n  File \"<ipython-input-7-354b2f8627b0>\", line 12, in __init__\n    self.target_values = tf.placeholder(shape=[None,], dtype=tf.float32)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4925, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?]\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?]\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-572e10d335ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepisode_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvantages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madvantages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mepisode_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             })\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?]\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_2', defined at:\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\n    handle._run()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\n    self.run()\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\n    yielded = self.gen.send(value)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 346, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 259, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 513, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\n    yielded = next(result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\n    return runner(coro)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-f7c785481313>\", line 3, in <module>\n    network = A2CNetwork(s_size, a_size)\n  File \"<ipython-input-7-354b2f8627b0>\", line 12, in __init__\n    self.target_values = tf.placeholder(shape=[None,], dtype=tf.float32)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 4925, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"/home/vasiko/anaconda3/envs/py36rl/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_2' with dtype float and shape [?]\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=[?], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 300\n",
    "min_batch_size = 32\n",
    "discount_factor = 0.95\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    episode_states = []\n",
    "    episode_rewards = []\n",
    "    episode_actions = []\n",
    "    episode_values = []\n",
    "    r_total = 0\n",
    "    \n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        pi, value = sess.run([network.policy, network.value], feed_dict={\n",
    "            network.states: [s]\n",
    "        })\n",
    "        action = np.random.choice(a_size, p=pi[0])\n",
    "        s1, r, done, _ = env.step(action)\n",
    "        \n",
    "        action_vec = possible_actions[action]\n",
    "        \n",
    "        episode_states.append(s)\n",
    "        episode_rewards.append(r)\n",
    "        episode_actions.append(action_vec)\n",
    "        episode_values.append(value[0][0])\n",
    "        r_total += r\n",
    "        \n",
    "        if done or len(episode_states) > min_batch_size:\n",
    "            target_value = 0\n",
    "            if not done: \n",
    "                target_value = sess.run(network.value, feed_dict={network.states: [s1]})[0]\n",
    "\n",
    "            target_values = np.zeros_like(episode_rewards)\n",
    "            for i in range(len(episode_states) - 1, -1, -1):\n",
    "                target_value = episode_rewards[i] +  discount_factor * target_value\n",
    "                target_values[i] = target_value\n",
    "\n",
    "#             print(target_values)\n",
    "#             print(episode_values)\n",
    "            advantages = target_values - np.array(episode_values)\n",
    "#             print(advantages)\n",
    "            loss, _ = sess.run([network.loss, network.optimize], feed_dict={\n",
    "                network.states: episode_states,\n",
    "                network.advantages: advantages,\n",
    "                network.actions: episode_actions\n",
    "            })\n",
    "\n",
    "\n",
    "            episode_states = []\n",
    "            episode_rewards = []\n",
    "            episode_actions = []\n",
    "            episode_values = []\n",
    "        \n",
    "        if done and episode % 10 == 0:\n",
    "            print(\"EPIDOSE {:0>5}: {}\".format(episode, r_total))\n",
    "        \n",
    "        s = s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36rl)",
   "language": "python",
   "name": "py36rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
